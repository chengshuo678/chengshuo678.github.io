<!DOCTYPE html>





<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.4.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.0" color="#222">

<link rel="stylesheet" href="/css/main.css?v=7.4.0">

<link rel="stylesheet" href="//fonts.cat.net/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/pace-js@1/themes/blue/pace-theme-minimal.css">
  <script src="//cdn.jsdelivr.net/npm/pace-js@1/pace.min.js"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.4.0',
    exturl: true,
    sidebar: {"position":"left","display":"post","offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>

  <meta name="description" content="KNN算法的理解。">
<meta name="keywords" content="机器学习,Numpy">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习-KNN算法">
<meta property="og:url" content="http://yoursite.com/2019/08/16/机器学习-KNN算法/index.html">
<meta property="og:site_name" content="飞鸿踏雪泥">
<meta property="og:description" content="KNN算法的理解。">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://note.youdao.com/yws/api/personal/file/WEB4184dca878d04a0887b7286c1ba9d436?method=download&shareKey=d3720ab97a07c17977664b620b96bdb2">
<meta property="og:image" content="https://note.youdao.com/yws/api/personal/file/WEB436486d4788779c3049d73bd9e2ce313?method=download&shareKey=371f904a95da7c413cf190d19f3cd6ac">
<meta property="og:updated_time" content="2019-08-17T06:49:19.377Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习-KNN算法">
<meta name="twitter:description" content="KNN算法的理解。">
<meta name="twitter:image" content="https://note.youdao.com/yws/api/personal/file/WEB4184dca878d04a0887b7286c1ba9d436?method=download&shareKey=d3720ab97a07c17977664b620b96bdb2">
  <link rel="canonical" href="http://yoursite.com/2019/08/16/机器学习-KNN算法/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>机器学习-KNN算法 | 飞鸿踏雪泥</title>
  








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">飞鸿踏雪泥</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-tags">
      
    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
      <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block post">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/08/16/机器学习-KNN算法/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="张城硕">
      <meta itemprop="description" content="博观而约取">
      <meta itemprop="image" content="/images/i.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="飞鸿踏雪泥">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">机器学习-KNN算法

          
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2019-08-16 15:17:00" itemprop="dateCreated datePublished" datetime="2019-08-16T15:17:00+08:00">2019-08-16</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2019-08-17 14:49:19" itemprop="dateModified" datetime="2019-08-17T14:49:19+08:00">2019-08-17</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/技术/" itemprop="url" rel="index"><span itemprop="name">技术</span></a></span>

                
                
              
            </span>
          

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <blockquote>
<p>KNN算法的理解。</p>
</blockquote>
<a id="more"></a>
<h4 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h4><blockquote>
<p>如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。<br>本文采用欧式距离，即两点之间的直接距离。</p>
</blockquote>
<h4 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h4><blockquote>
<p>通过你的邻居，判断你是哪种类型</p>
</blockquote>
<h4 id="KNN算法流程总结"><a href="#KNN算法流程总结" class="headerlink" title="KNN算法流程总结"></a>KNN算法流程总结</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">1）计算已知类别数据集中的点与当前点之间的距离</span><br><span class="line">2）按距离递增次序排序</span><br><span class="line">3）选取与当前点距离最小的k个点</span><br><span class="line">4）统计前k个点所在的类别出现的频率</span><br><span class="line">5）返回前k个点出现频率最高的类别作为当前点的预测分类</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.neighbors <span class="keyword">import</span> KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"><span class="comment"># achieve data</span></span><br><span class="line">x = [[<span class="number">1</span>],[<span class="number">2</span>],[<span class="number">3</span>],[<span class="number">-1</span>],[<span class="number">-4</span>]]</span><br><span class="line">y = [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">-1</span>]</span><br><span class="line"></span><br><span class="line">estimator = KNeighborsClassifier(n_neighbors=<span class="number">3</span>)</span><br><span class="line">estimator.fit(x,y)</span><br><span class="line">result = estimator.predict([[<span class="number">-3</span>]])</span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure>
<pre><code>[-1]
</code></pre><h4 id="问题一：距离选取"><a href="#问题一：距离选取" class="headerlink" title="问题一：距离选取"></a>问题一：距离选取</h4><p>1.距离公式，除了欧式距离，还有哪些距离公式可以使用？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">（1）欧式距离（两点距离问题）：两个点在空间中的距离。</span><br><span class="line">（2）曼哈顿距离（城市街区问题）：在曼哈顿街区要从一个十字路口开车到另一个十字路口，驾驶距离显然不是两点间的直线距离。这个实际驾驶距离就是“曼哈顿距离”。曼哈顿距离也称为“城市街区距离”(City Block distance)。</span><br><span class="line">    d(i,j)=|X1-X2|+|Y1-Y2|</span><br><span class="line">（3）切比雪夫距离 (Chebyshev Distance)：国际象棋中，国王可以直行、横行、斜行，所以国王走一步可以移动到相邻8个方格中的任意一个。国王从格子(x1,y1)走到格子(x2,y2)最少需要多少步？这个距离就叫切比雪夫距离。在公式里体现就是某个维度上的最大距离。</span><br><span class="line">（4）闵可夫斯基距离(Minkowski Distance)：闵氏距离不是一种距离，而是一组距离的定义，是对多个距离度量公式的概括性的表述。</span><br><span class="line">两个n维变量a(x11,x12,…,x1n)与b(x21,x22,…,x2n)间的闵可夫斯基距离定义为：</span><br><span class="line">其中p是一个变参数：</span><br><span class="line">当p=1时，就是曼哈顿距离；</span><br><span class="line">当p=2时，就是欧氏距离；</span><br><span class="line">当p→∞时，就是切比雪夫距离。</span><br><span class="line">根据p的不同，闵氏距离可以表示某一类/种的距离</span><br></pre></td></tr></table></figure>
<p>小结：</p>
<blockquote>
<p>1 闵氏距离，包括曼哈顿距离、欧氏距离和切比雪夫距离都存在明显的缺点:<br>e.g. 二维样本(身高[单位:cm],体重[单位:kg]),现有三个样本：a(180,50)，b(190,50)，c(180,60)。</p>
<p>a与b的闵氏距离（无论是曼哈顿距离、欧氏距离或切比雪夫距离）等于a与c的闵氏距离。但实际上身高的10cm并不能和体重的10kg划等号。</p>
</blockquote>
<p>闵氏距离的缺点：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">​ (1)将各个分量的量纲(scale)，也就是“单位”相同的看待了;</span><br><span class="line">​ (2)未考虑各个分量的分布（期望，方差等）可能是不同的。</span><br></pre></td></tr></table></figure></p>
<h4 id="改进"><a href="#改进" class="headerlink" title="改进"></a>改进</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">标准化欧氏距离 (Standardized EuclideanDistance)：标准化欧氏距离是针对欧氏距离的缺点而作的一种改进。</span><br><span class="line">思路：既然数据各维分量的分布不一样，那先将各个分量都“标准化”到均值、方差相等。</span><br></pre></td></tr></table></figure>
<h4 id="其他距离"><a href="#其他距离" class="headerlink" title="其他距离"></a>其他距离</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">(1)余弦距离(Cosine Distance):</span><br><span class="line">几何中，夹角余弦可用来衡量两个向量方向的差异；机器学习中，借用这一概念来衡量样本向量之间的差异。</span><br><span class="line">(2)汉明距离(Hamming Distance):</span><br><span class="line">两个等长字符串s1与s2的汉明距离为：将其中一个变为另外一个所需要作的最小字符替换次数。</span><br><span class="line">(3)杰卡德距离(Jaccard Distance):</span><br><span class="line">杰卡德相似系数(Jaccard similarity coefficient)：两个集合A和B的交集元素在A，B的并集中所占的比例，称为两个集合的杰卡德相似系数，用符号J(A,B)。</span><br><span class="line">杰卡德距离(Jaccard Distance)：与杰卡德相似系数相反，用两个集合中不同元素占所有元素的比例来衡量两个集合的区分度</span><br><span class="line">（4）马氏距离(Mahalanobis Distance):马氏距离是由印度统计学家马哈拉诺比斯提出的，表示数据的协方差距离。它是一种有效的计算两个位置样本集的相似度的方法。马氏距离也可以定义为两个服从同一分布并且其协方差矩阵为∑的随机变量的差异程度：如果协方差矩阵为单位矩阵，马氏距离就简化为欧式距离；如果协方差矩阵为对角矩阵，则其也可称为正规化的欧式距离。</span><br><span class="line">马氏距离特性：</span><br><span class="line"></span><br><span class="line">    1.量纲无关，排除变量之间的相关性的干扰；</span><br><span class="line"></span><br><span class="line">    2.马氏距离的计算是建立在总体样本的基础上的，如果拿同样的两个样本，放入两个不同的总体中，最后计算得出的两个样本间的马氏距离通常是不相同的，除非这两个总体的协方差矩阵碰巧相同；</span><br><span class="line"></span><br><span class="line">    3 .计算马氏距离过程中，要求总体样本数大于样本的维数，否则得到的总体样本协方差矩阵逆矩阵不存在，这种情况下，用欧式距离计算即可。</span><br><span class="line"></span><br><span class="line">    4.还有一种情况，满足了条件总体样本数大于样本的维数，但是协方差矩阵的逆矩阵仍然不存在，比如三个样本点（3，4），（5，6），（7，8），这种情况是因为这三个样本在其所处的二维空间平面内共线。这种情况下，也采用欧式距离计算。</span><br></pre></td></tr></table></figure>
<h4 id="问题二：K值的选取"><a href="#问题二：K值的选取" class="headerlink" title="问题二：K值的选取"></a>问题二：K值的选取</h4><blockquote>
<p>2.选取K值的大小？<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">K值过小：</span><br><span class="line">容易受到异常点的影响</span><br><span class="line">k值过大：</span><br><span class="line">受到样本均衡的问题</span><br></pre></td></tr></table></figure></p>
</blockquote>
<h5 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h5><p>参考：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">K值选择问题，李航博士的一书「统计学习方法」上所说：</span><br><span class="line"></span><br><span class="line">1) 选择较小的K值，就相当于用较小的领域中的训练实例进行预测，“学习”近似误差会减小，只有与输入实例较近或相似的训练实例才会对预测结果起作用，与此同时带来的问题是“学习”的估计误差会增大，换句话说，K值的减小就意味着整体模型变得复杂，容易发生过拟合；</span><br><span class="line"></span><br><span class="line">2) 选择较大的K值，就相当于用较大领域中的训练实例进行预测，其优点是可以减少学习的估计误差，但缺点是学习的近似误差会增大。这时候，与输入实例较远（不相似的）训练实例也会对预测器作用，使预测发生错误，且K值的增大就意味着整体的模型变得简单。</span><br><span class="line"></span><br><span class="line">3) K=N（N为训练样本个数），则完全不足取，因为此时无论输入实例是什么，都只是简单的预测它属于在训练实例中最多的类，模型过于简单，忽略了训练实例中大量有用信息。</span><br></pre></td></tr></table></figure></p>
<p>在实际应用中，K值一般取一个比较小的数值，例如采用交叉验证法（简单来说，就是把训练数据在分成两组:训练集和验证集）来选择最优的K值。</p>
<h4 id="近似误差："><a href="#近似误差：" class="headerlink" title="近似误差："></a>近似误差：</h4><blockquote>
<p>对现有训练集的训练误差，关注训练集.</p>
<p>如果近似误差过小可能会出现过拟合的现象，对现有的训练集能有很好的预测，但是对未知的测试样本将会出现较大偏差的预测。</p>
<p>模型本身不是最接近最佳模型。</p>
<h4 id="估计误差："><a href="#估计误差：" class="headerlink" title="估计误差："></a>估计误差：</h4><p>理解为对测试集的测试误差，关注测试集。</p>
<p>估计误差小说明对未知数据的预测能力好。</p>
<p>模型本身最接近最佳模型。</p>
</blockquote>
<p>鸢尾花代码实现</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">&quot;&quot;&quot;</span><br><span class="line">1.获取数据集</span><br><span class="line">2，数据基本处理</span><br><span class="line">3. 特征工程</span><br><span class="line">4. 机器学习（模型训练）</span><br><span class="line">5. 模型评估</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">from sklearn.datasets import load_iris</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"># 1.获取数据集</span><br><span class="line">iris = load_iris()</span><br><span class="line"># 2，数据基本处理</span><br><span class="line"># 2.1 数据分割</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=23, test_size=0.1)</span><br><span class="line"></span><br><span class="line"># 3. 特征工程</span><br><span class="line"># 3.1 实例化一个转化器</span><br><span class="line">transfer = StandardScaler()</span><br><span class="line"># 3.2 调用fit_transform方法</span><br><span class="line">x_train = transfer.fit_transform(x_train)</span><br><span class="line">x_test = transfer.fit_transform(x_test)</span><br><span class="line"></span><br><span class="line"># 4. 机器学习（模型训练）</span><br><span class="line"># 4.1 实例化一个估计器</span><br><span class="line">estimator = KNeighborsClassifier(n_neighbors=5)</span><br><span class="line"># 4.2 模型训练</span><br><span class="line">estimator.fit(x_train,y_train)</span><br><span class="line"># 5. 模型评估</span><br><span class="line"># 5.1 输出预测值</span><br><span class="line">y_pre = estimator.predict(x_test)</span><br><span class="line">print(&quot;预测值是：\n&quot;, y_pre)</span><br><span class="line"></span><br><span class="line"># 5.2 输出准确率</span><br><span class="line">ret = estimator.score(x_test, y_test)</span><br><span class="line">print(&quot;准确率：\n&quot;, ret)</span><br></pre></td></tr></table></figure>
<h4 id="KNN-算法总结"><a href="#KNN-算法总结" class="headerlink" title="KNN 算法总结"></a>KNN 算法总结</h4><h5 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h5><ul>
<li>简单有效</li>
<li>重新训练代价低</li>
<li>适合类域交叉样本：KNN方法主要靠周围有限的邻近的样本,而不是靠判别类域的方法来确定所属类别的，因此对于类域的交叉或重叠较多的待分样本集来说，KNN方法较其他方法更为适合。</li>
<li>该算法比较适用于样本容量比较大的类域的自动分类，而那些样本容量较小的类域采用这种算法比较容易产生误分。</li>
</ul>
<h5 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h5><ul>
<li>惰性算法</li>
<li>类别评分不是规格化</li>
<li>对不均衡的样本不擅长<br>当样本不平衡时，如一个类的样本容量很大，而其他类样本容量很小时，有可能导致当输入一个新样本时，该样本的K个邻居中大容量类的样本占多数。该算法只计算“最近的”邻居样本，某一类的样本数量很大，那么或者这类样本并不接近目标样本，或者这类样本很靠近目标样本。无论怎样，数量并不能影响运行结果。可以采用权值的方法（和该样本距离小的邻居权值大）来改进。</li>
<li>计算量较大<br>目前常用的解决方法是事先对已知样本点进行剪辑，事先去除对分类作用不大的样本。</li>
</ul>
<h4 id="【引入】交叉验证-amp-网格搜索"><a href="#【引入】交叉验证-amp-网格搜索" class="headerlink" title="【引入】交叉验证&amp;网格搜索"></a>【引入】交叉验证&amp;网格搜索</h4><h5 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h5><blockquote>
<p>交叉验证：将拿到的训练数据，分为训练和验证集。以下图为例：将数据分成4份，其中一份作为验证集。然后经过4次(组)的测试，每次都更换不同的验证集。即得到4组模型的结果，取平均值作为最终结果。又称4折交叉验证。</p>
<p>目的：为了让被评估的模型更加准确可信<br>为了让从训练得到模型结果更加准确。做以下处理<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">训练集：训练集+验证集</span><br><span class="line">测试集：测试集</span><br></pre></td></tr></table></figure></p>
</blockquote>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEB4184dca878d04a0887b7286c1ba9d436?method=download&amp;shareKey=d3720ab97a07c17977664b620b96bdb2" alt="avater"></p>
<h5 id="网格搜索"><a href="#网格搜索" class="headerlink" title="网格搜索"></a>网格搜索</h5><blockquote>
<p>通常情况下，有很多参数是需要手动指定的（如k-近邻算法中的K值），这种叫超参数。但是手动过程繁杂，所以需要对模型预设几种超参数组合。每组超参数都采用交叉验证来进行评估。最后选出最优参数组合建立模型。</p>
</blockquote>
<p><img src="https://note.youdao.com/yws/api/personal/file/WEB436486d4788779c3049d73bd9e2ce313?method=download&amp;shareKey=371f904a95da7c413cf190d19f3cd6ac" alt="atater"></p>
<h5 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h5><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sklearn.model_selection.GridSearchCV(estimator, param_grid=None,cv=None)</span><br><span class="line">estimator -- 选择了哪个训练模型</span><br><span class="line">param_grid -- 需要传递的超参数</span><br><span class="line">cv -- 几折交叉验证</span><br></pre></td></tr></table></figure>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">&quot;&quot;&quot;</span><br><span class="line">1.获取数据集</span><br><span class="line">2，数据基本处理</span><br><span class="line">3. 特征工程</span><br><span class="line">4. 机器学习（模型训练）</span><br><span class="line">5. 模型评估</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">from sklearn.datasets import load_iris</span><br><span class="line">from sklearn.model_selection import train_test_split, GridSearchCV</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line"></span><br><span class="line"># 1.获取数据集</span><br><span class="line">iris = load_iris()</span><br><span class="line"># 2，数据基本处理</span><br><span class="line"># 2.1 数据分割</span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2)</span><br><span class="line"></span><br><span class="line"># 3. 特征工程</span><br><span class="line"># 3.1 实例化一个转化器</span><br><span class="line">transfer = StandardScaler()</span><br><span class="line"># 3.2 调用fit_transform方法</span><br><span class="line">x_train = transfer.fit_transform(x_train)</span><br><span class="line">x_test = transfer.fit_transform(x_test)</span><br><span class="line"></span><br><span class="line"># 4. 机器学习（模型训练）</span><br><span class="line"># 4.1 实例化一个估计器</span><br><span class="line">estimator = KNeighborsClassifier(n_neighbors=1)</span><br><span class="line"></span><br><span class="line"># 4.2 调用交叉验证网格搜索模型</span><br><span class="line">param_grid = &#123;&quot;n_neighbors&quot;: [1, 3, 5, 7, 9]&#125;</span><br><span class="line">estimator = GridSearchCV(estimator, param_grid=param_grid, cv=10, n_jobs=4)</span><br><span class="line"></span><br><span class="line"># 4.3 模型训练</span><br><span class="line">estimator.fit(x_train, y_train)</span><br><span class="line"># 5. 模型评估</span><br><span class="line"># 5.1 输出预测值</span><br><span class="line">y_pre = estimator.predict(x_test)</span><br><span class="line">print(&quot;预测值是：\n&quot;, y_pre)</span><br><span class="line"></span><br><span class="line"># 5.2 输出准确率</span><br><span class="line">ret = estimator.score(x_test, y_test)</span><br><span class="line">print(&quot;准确率：\n&quot;, ret)</span><br><span class="line"></span><br><span class="line"># 5.3 其他平均指标</span><br><span class="line">print(&quot;最好的模型:\n&quot;, estimator.best_estimator_)</span><br><span class="line">print(&quot;最好的结果:\n&quot;, estimator.best_score_)</span><br><span class="line">print(&quot;整体模型结果:\n&quot;, estimator.cv_results_)</span><br></pre></td></tr></table></figure>

    </div>

    
    
    
        
      
        <div id="reward-container">
  <div>觉得不错？</div>
  <button id="reward-button" disable="enable" onclick="var qr = document.getElementById(&quot;qr&quot;); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
        
      
      <div style="display: inline-block">
        <img src="/images/wechatPay.png" alt="张城硕 微信支付">
        <p>微信支付</p>
      </div>

  </div>
</div>

      

      <footer class="post-footer">
          
            
          
          <div class="post-tags">
            
              <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
            
              <a href="/tags/Numpy/" rel="tag"># Numpy</a>
            
          </div>
        

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2019/08/15/机器学习实践Numpy【3】矩阵/" rel="next" title="机器学习实践Numpy【3】矩阵">
                  <i class="fa fa-chevron-left"></i> 机器学习实践Numpy【3】矩阵
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/2019/08/17/机器学习-线性回归/" rel="prev" title="机器学习-线性回归">
                  机器学习-线性回归 <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </div>
  
  
  
  </article>

  </div>


          </div>
          
    
    <div class="comments" id="gitalk-container"></div>
  

        </div>
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#定义"><span class="nav-text">定义</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#思想"><span class="nav-text">思想</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#KNN算法流程总结"><span class="nav-text">KNN算法流程总结</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#问题一：距离选取"><span class="nav-text">问题一：距离选取</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#改进"><span class="nav-text">改进</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#其他距离"><span class="nav-text">其他距离</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#问题二：K值的选取"><span class="nav-text">问题二：K值的选取</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#解决方法"><span class="nav-text">解决方法</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#近似误差："><span class="nav-text">近似误差：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#估计误差："><span class="nav-text">估计误差：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#KNN-算法总结"><span class="nav-text">KNN 算法总结</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#优点"><span class="nav-text">优点</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#缺点"><span class="nav-text">缺点</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#【引入】交叉验证-amp-网格搜索"><span class="nav-text">【引入】交叉验证&amp;网格搜索</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#交叉验证"><span class="nav-text">交叉验证</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#网格搜索"><span class="nav-text">网格搜索</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#代码实现"><span class="nav-text">代码实现</span></a></li></ol></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image"
      src="/images/i.jpg"
      alt="张城硕">
  <p class="site-author-name" itemprop="name">张城硕</p>
  <div class="site-description" itemprop="description">博观而约取</div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">33</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2015 – <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">张城硕</span>
</div>
  <div class="powered-by">由 <span class="exturl theme-link" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> 强力驱动 v3.9.0</div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">主题 – <span class="exturl theme-link" data-url="aHR0cHM6Ly90aGVtZS1uZXh0Lm9yZw==">NexT.Pisces</span> v7.4.0</div>

        












        
      </div>
    </footer>
  </div>

  


  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
<script src="/js/utils.js?v=7.4.0"></script><script src="/js/motion.js?v=7.4.0"></script>
<script src="/js/schemes/pisces.js?v=7.4.0"></script>
<script src="/js/next-boot.js?v=7.4.0"></script>



  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>





















  

  
    
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    
  

  

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">

<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID: '6ab2d7892119e92e3f93',
      clientSecret: '581616bbf0f940d2668251b19b02ad337dc5a7a4',
      repo: 'chengshuoBlog',
      owner: '',
      admin: ['chengshuo678'],
      id: '9f7f37450d954c19da8fdd2081af85f5',
        language: window.navigator.language || window.navigator.userLanguage,
      
      distractionFreeMode: 'true'
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
</script>

</body>
</html>
